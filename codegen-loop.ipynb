{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "API_KEY=\"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\"\n",
    "model=\"codellama-34b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_CodeGenerator(mode, user_prompt, num_loops, previous_prompts_responses=None):\n",
    "    if previous_prompts_responses is None:\n",
    "        previous_prompts_responses = []\n",
    "\n",
    "    for i in range(num_loops):\n",
    "        print(\"*****\\n\\n\\n\")\n",
    "        print(f\"\\nModel {mode} Iteration {i+1}:\")\n",
    "        if mode == \"Starter\":\n",
    "            gprompt,generated_code = generate_initial_code_based_on_prompt(user_prompt, previous_prompts_responses)\n",
    "        elif mode == \"Debug\":\n",
    "            gprompt,generated_code = analyze_code_for_errors(previous_prompts_responses)\n",
    "        elif mode == \"Optimize\":\n",
    "            gprompt,generated_code = optimize_code(previous_prompts_responses)\n",
    "        elif mode == \"Build test\":\n",
    "            gprompt,generated_code = build_tester_code(previous_prompts_responses)\n",
    "        elif mode == \"Compile test\":\n",
    "            gprompt = \"Compile and test\"\n",
    "            generated_code, response_message = compile_and_run_tests(previous_prompts_responses)\n",
    "            print(response_message)\n",
    "        else:\n",
    "            return \"Invalid mode selected\"\n",
    "        print(\"*****\\n\\n\\n\")\n",
    "        \n",
    "\n",
    "        print(generated_code)\n",
    "        previous_prompts_responses.append({\"role\": \"user\", \"content\": gprompt})\n",
    "        previous_prompts_responses.append({\"role\": \"assistant\", \"content\": generated_code})\n",
    "\n",
    "        # Self-diagnosis prompts\n",
    "        self_diagnosis_prompts = [\n",
    "            \"Identify potential errors in the generated code\",\n",
    "            \"Suggest ways to make the generated code more efficient\",\n",
    "            \"Provide any additional improvements or best practices for the generated code\"\n",
    "        ]\n",
    "\n",
    "        if mode != \"Compile test\" : \n",
    "            extracted_code = extract_generated_code_from_chat_log(previous_prompts_responses[-1][\"content\"])\n",
    "        else:\n",
    "            extracted_code = generated_code\n",
    "        \n",
    "        if mode == \"Starter\":\n",
    "            for prompt in self_diagnosis_prompts:\n",
    "                prompt1 = prompt +  \". Then output revised code to reflect this feedback.\\n\\n\"\n",
    "    #            self_diagnosis_response = call_pplx_api(prompt1, previous_prompts_responses)\n",
    "                prompt1 += \"Original user prompt:\"\n",
    "                prompt1 += user_prompt\n",
    "                prompt1 += \"Generated code:\"\n",
    "                prompt1 += extracted_code\n",
    "                prompt1 += \"Self-diagnosis response:<Enter response here>\\n\\n\"\n",
    "                prompt1 += \"Revised code:\"\n",
    "\n",
    "                self_diagnosis_response = call_pplx_api(prompt1, [])\n",
    "                print(f\"\\n{prompt1}\")\n",
    "                print(\"LLM response:\\n***********\\n\")\n",
    "                print(self_diagnosis_response)\n",
    "                previous_prompts_responses.append({\"role\": \"user\", \"content\": prompt1})\n",
    "                previous_prompts_responses.append({\"role\": \"assistant\", \"content\": self_diagnosis_response})\n",
    "                extracted_code = extract_generated_code_from_chat_log(self_diagnosis_response)\n",
    "\n",
    "    return extracted_code, previous_prompts_responses\n",
    "\n",
    "def generate_initial_code_based_on_prompt(user_prompt, previous_prompts_responses):\n",
    "    prompt = f\"Write code based on the following prompt: {user_prompt}\"\n",
    "    return prompt, call_pplx_api(prompt, previous_prompts_responses)\n",
    "\n",
    "def analyze_code_for_errors(previous_prompts_responses):\n",
    "    prompt = \"Analyze the previously generated code for errors and provide corrections\"\n",
    "    code_to_analyze = previous_prompts_responses[-1][\"content\"]\n",
    "    prompt += f\"\\n\\nCode to analyze:\\n{code_to_analyze}\"\n",
    "    return prompt, call_pplx_api(prompt, previous_prompts_responses)\n",
    "\n",
    "def optimize_code(previous_prompts_responses):\n",
    "    prompt = \"Optimize the previously generated code for performance and efficiency\"\n",
    "    code_to_optimize = previous_prompts_responses[-1][\"content\"]\n",
    "    prompt += f\"\\n\\nCode to optimize:\\n{code_to_optimize}\"\n",
    "    return prompt,call_pplx_api(prompt, previous_prompts_responses)\n",
    "\n",
    "def build_tester_code(previous_prompts_responses):\n",
    "    prompt = \"Build tester code for the previously generated code to ensure its correctness\"\n",
    "    code_to_test = previous_prompts_responses[-1][\"content\"]\n",
    "    prompt += f\"\\n\\nCode to build tester for:\\n{code_to_test}\"\n",
    "    return prompt,call_pplx_api(prompt, previous_prompts_responses)\n",
    "\n",
    "\n",
    "def extract_generated_code_from_chat_log(text_):\n",
    "    prompt = \"\"\"Return only the last block of valid python code from this chat session log. Only output syntactically correct code. No explanations or details. Remove any leading or trailing whitespace or quotes.\n",
    "    Example:\n",
    "    Input log:\n",
    "    User: Write code to add two numbers. Then write code to multiply two numbers. Then write code to subtract two numbers. Then test the add and multiply functions.\n",
    "    def add(a, b):\n",
    "        return a + b\n",
    "    def subtract(a, b):\n",
    "        return a - b\n",
    "    def multiply(a, b):\n",
    "        return a * b\n",
    "    add(1, 2)\n",
    "    multiply(3, 4)\n",
    "    Extracted Code:\n",
    "    def add(a, b):\n",
    "        return a + b\n",
    "    def subtract(a, b):\n",
    "        return a - b\n",
    "    def multiply(a, b):\n",
    "        return a * b\n",
    "    add(1, 2)\n",
    "    multiply(3, 4)\n",
    "\n",
    "    Input log:    \n",
    "    \"\"\"\n",
    "    prompt += f\"\\n\\n:\\n{text_}\"\n",
    "    prompt += \"\\n\\nExtracted Code:\"\n",
    "    return  call_pplx_api(prompt, [])\n",
    "    \n",
    "\n",
    "\n",
    "def compile_and_run_tests(previous_prompts_responses):\n",
    "#    prompt = \"Compile the previously generated code and run tests to verify its functionality\"\n",
    "    \n",
    "    extracted_code = extract_generated_code_from_chat_log(previous_prompts_responses[-1][\"content\"])\n",
    "\n",
    "\n",
    "    #prompt = \"Return only the final code from this chat session log. Only output syntactically correct code. No explanations or details\"\n",
    "    #code_to_compile_and_test = previous_prompts_responses[-1][\"content\"]\n",
    "\n",
    "    #prompt += f\"\\n\\n:\\n{code_to_compile_and_test}\"\n",
    "#    resp =  call_pplx_api(prompt, extracted_code)\n",
    " #   code_to_compile_and_test = resp\n",
    "\n",
    "    # Specify the path to the Python file you want to compile\n",
    "    source_file = \"example.py\"\n",
    "\n",
    "    # write the code to a file\n",
    "    with open(source_file, \"w\") as file:\n",
    "        file.write(extracted_code)\n",
    "\n",
    "    # Compile the Python file\n",
    "    response = \"\"\n",
    "    try:\n",
    "        #py_compile.compile(source_file)\n",
    "        py_compile.compile(source_file, doraise=True)\n",
    "\n",
    "        response = f\"Successfully compiled {source_file}\"\n",
    "    except py_compile.PyCompileError as e:\n",
    "        response = f\"Compilation failed: {e}\"\n",
    "\n",
    "    return extracted_code, response.strip()\n",
    "\n",
    "\n",
    " #       prompt += f\"\\n\\nCode to compile and test:\\n{code_to_compile_and_test}\"\n",
    " #       return call_pplx_api(prompt, previous_prompts_responses)\n",
    "\n",
    "def call_pplx_api(prompt, previous_prompts_responses=None):\n",
    "    print(\"  ____  \")\n",
    "    print(\" / __ \\\\ \")\n",
    "    print(\"/ /  \\\\ \\\\\")\n",
    "    print(\"\\\\ \\\\__/ /\")\n",
    "    print(\" \\\\____/ \")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    model = \"codellama-34b-instruct\"\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You're a super powerful code copilot capable of running loops. You are top coder at Google. You always output python code and decline to output code in any other language.\"\n",
    "            ),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    if previous_prompts_responses:\n",
    "        messages.extend(previous_prompts_responses)\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    })\n",
    "\n",
    "    client = OpenAI(api_key=API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "previous_prompts_responses = []\n",
    "\n",
    "\n",
    "# Main program\n",
    "while True:\n",
    "    print(\"New code generation iteration\\n\")\n",
    "    ## print ascii art for B\n",
    "    print(\"  ____  \")\n",
    "    print(\" / __ \\\\ \")\n",
    "    print(\"/ /  \\\\ \\\\\")\n",
    "    print(\"\\\\ \\\\__/ /\")\n",
    "    print(\" \\\\____/ \")\n",
    "    print(\"  ____  \")\n",
    "    print(\" / __ \\\\ \")\n",
    "    print(\"/ /  \\\\ \\\\\")\n",
    "    print(\"\\\\ \\\\__/ /\")\n",
    "    print(\" \\\\____/ \")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "    user_input = \"\"\n",
    "    selected_mode = input(\"Enter the mode (Starter/Debug/Optimize/Build test/Compile test/Exit): \")\n",
    "    if selected_mode == \"Exit\":\n",
    "        break\n",
    "    elif selected_mode not in [\"Starter\", \"Debug\", \"Optimize\", \"Build test\", \"Compile test\"]:\n",
    "        print(\"Invalid mode selected\")\n",
    "        continue\n",
    "    elif selected_mode == \"Starter\" : \n",
    "        user_input = input(\"Enter the user prompt: \")\n",
    "\n",
    "    num_loops = int(input(\"Enter the number of loops for each step: \"))\n",
    "    generated_code, previous_prompts_responses = LLM_CodeGenerator(selected_mode, user_input, num_loops, previous_prompts_responses=previous_prompts_responses)\n",
    "    print(\"\\nFinal generated code:\")\n",
    "    print(generated_code)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
